{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as dtst\n",
    "from torch import optim\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random.seed(99)\n",
    "torch.manual_seed(99)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23aad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path de la carpeta donde se ubican las imágenes de entrenamiento\n",
    "data_folder = './images'\n",
    "\n",
    "# Tamaño que deseamos que tengan las imágenes\n",
    "image_size = 128\n",
    "# Tamaño del lote de imágenes\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "dsimgs = dtst.ImageFolder(\n",
    "    root=data_folder,\n",
    "    transform=transforms.Compose([\n",
    "        # Se usa el resize en caso no todas las imágenes de entrada tengan el tamaño de 128px\n",
    "        transforms.Resize(image_size),\n",
    "        # CenterCrop busca recortar la imagen en caso sea muy grande al tamaño dado\n",
    "        transforms.CenterCrop(image_size),\n",
    "        # ToTensor convierte finalmente la imagen a tensor\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize permite la normalización de la información\n",
    "        # El problema encontrado es que necesitamos hallar la desviación estandar\n",
    "        # media de toda la información para realizar una correcta normalización\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]))\n",
    "\n",
    "dt_loader = DataLoader(dsimgs,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1,\n",
    "                       droplast=True)\n",
    "\n",
    "# Forzamos el uso de CUDA\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817e5d6",
   "metadata": {},
   "source": [
    "#### Visualización de lote de imágenes de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993fde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_imagenes = next(iter(dt_loader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Imágenes de entrenamiento\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        make_grid(batch_imagenes[0].to(device)[:64], padding=2,\n",
    "                  normalize=True).cpu(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b93ded",
   "metadata": {},
   "source": [
    "#### Función generadora de vector de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_generator(n, dimension, device):\n",
    "    return torch.randn(n, dimension, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544406b",
   "metadata": {},
   "source": [
    "#### Función de visualización durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca45a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 64, 64)):\n",
    "    '''\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569010d3",
   "metadata": {},
   "source": [
    "#### Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d87164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_z es la cantidad de canales del vector de ruido de entrada\n",
    "dim_z = 200\n",
    "# ch_rgb son los canales 3 canales de color\n",
    "ch_rgb = 3\n",
    "# gd_hidd_ch es el valor base que tendrá la dimensión de los tensores \n",
    "# durante las convoluciones ocultas en el generador y en el discriminador\n",
    "gd_hidd_ch = 64 \n",
    "# el ratio de aprendizaje es la distancia que recorre el punto de \n",
    "# optimización al tomarse la gradiente del modelo para encontrar \n",
    "# mínimos locales o globales y así optimizar el modelo\n",
    "lr = 0.0005\n",
    "\n",
    "# Función de inicialización de pesos\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3de17",
   "metadata": {},
   "source": [
    "### RED GENERADORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class redGeneradora(nn.Module):\n",
    "    def __init__(self, dim_z=200, ch_rgb=3, hidd_ch=64):\n",
    "        \n",
    "        super(redGeneradora, self).__init__()\n",
    "        \n",
    "        self.z_dim=dim_z\n",
    "        self.main = nn.Sequential(\n",
    "            self.gen_blocks(dim_z, hidd_ch*8, stride=1, padding=0),\n",
    "            self.gen_blocks(hidd_ch*8, hidd_ch*4),\n",
    "            self.gen_blocks(hidd_ch*4, hidd_ch*2),\n",
    "            self.gen_blocks(hidd_ch*2, hidd_ch),\n",
    "            self.gen_blocks(hidd_ch, hidd_ch), ## ¿Afecta las ConvT a un mismo nivel?\n",
    "            self.gen_blocks(hidd_ch, ch_rgb,f_layer=True)  # Obtenemos un \"Tensor\" 3*128*128\n",
    "        )\n",
    "    \n",
    "    def gen_blocks(self, inp_ch, out_ch, kernel=4, stride=2, padding=1, f_layer=False):\n",
    "        if not f_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(inp_ch, out_ch, kernel, stride, padding, bias = False), # Probando bias = False\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(inp_ch, out_ch, kernel, stride, padding, bias = False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, input_t):\n",
    "        # El tensor de ruido se redimensiona a 1*1*dim_Z donde \n",
    "        # dim_Z son los canales de entrada\n",
    "        x = input_t.view(len(input_t), self.z_dim, 1, 1)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832ee43",
   "metadata": {},
   "source": [
    "##### Instanciado del modelo generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo\n",
    "anime_gen = redGeneradora(dim_z, ch_rgb, gd_hidd_ch).to(device)\n",
    "\n",
    "# Asignamos pesos a la red generadora\n",
    "anime_gen = anime_gen.apply(weights_init)\n",
    "\n",
    "# Instanciamos su optimizador\n",
    "gen_optim = torch.optim.Adam(anime_gen.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfdcfe",
   "metadata": {},
   "source": [
    "### RED DISCRIMINADORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class redDiscriminadora(nn.Module):\n",
    "    def __init__(self, dim_z=200, ch_rgb=3, hidd_ch=64):\n",
    "        \n",
    "        super(redDiscriminadora, self).__init__()\n",
    "        \n",
    "        self.z_dim=dim_z\n",
    "        # Necesitamos realizar el proceso inverso\n",
    "        self.main = nn.Sequential(\n",
    "            # la entrada sería 3*128*128\n",
    "            self.gen_blocks(ch_rgb, hidd_ch),\n",
    "            self.gen_blocks(hidd_ch, hidd_ch),\n",
    "            self.gen_blocks(hidd_ch, hidd_ch*2),\n",
    "            self.gen_blocks(hidd_ch*2, hidd_ch*4),\n",
    "            self.gen_blocks(hidd_ch*4, hidd_ch*8),\n",
    "            self.gen_blocks(hidd_ch*8, 1,f_layer=True)  # Obtenemos un \"Tensor\" 1*128*128\n",
    "        )\n",
    "    \n",
    "    def gen_blocks(self, inp_ch, out_ch, kernel=4, stride=2, padding=1, f_layer=False):\n",
    "        if not f_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp_ch, out_ch, kernel, stride, padding, bias = False), # Probando bias = False\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU( inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp_ch, out_ch, kernel, 1, 0, bias = False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, input_arr):\n",
    "        y = self.main(input_arr)\n",
    "        return y.view(len(y), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57f52f",
   "metadata": {},
   "source": [
    "##### Instanciando el modelo Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo\n",
    "anime_dis = redDiscriminadora(dim_z, ch_rgb, gd_hidd_ch).to(device)\n",
    "\n",
    "# Asignamos pesos a la red generadora\n",
    "anime_dis = anime_dis.apply(weights_init)\n",
    "\n",
    "# Instanciamos su optimizador\n",
    "dis_optim = torch.optim.Adam(anime_dis.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9576f",
   "metadata": {},
   "source": [
    "##### Instanciamos la función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_losses(cur_step, display_step, generator_losses,\n",
    "                   discriminator_losses):\n",
    "    if cur_step % display_step == 0 and cur_step > 0:\n",
    "        gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "        disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "        step_bins = 20\n",
    "        x_axis = sorted(\n",
    "            [i * step_bins\n",
    "             for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
    "        num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "        plt.plot(range(num_examples // step_bins),\n",
    "                 torch.Tensor(generator_losses[:num_examples]).view(\n",
    "                     -1, step_bins).mean(1),\n",
    "                 label=\"Generator Loss\")\n",
    "        plt.plot(range(num_examples // step_bins),\n",
    "                 torch.Tensor(discriminator_losses[:num_examples]).view(\n",
    "                     -1, step_bins).mean(1),\n",
    "                 label=\"Discriminator Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    elif cur_step == 0:\n",
    "        print(\"Tu modelo se está entrenando, espero funcione :'D \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8fe40e",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46764875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "display_step = 250\n",
    "\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for real, _ in tqdm(dt_loader):\n",
    "        \n",
    "        # cur_batch_size: Cantidad de datos del batch del dataloader?\n",
    "        cur_batch_size = len(real) \n",
    "        # real: iterador\n",
    "        real = real.to(device)\n",
    "        \n",
    "        #######################################\n",
    "        ##   Actualizamos el discriminador   ##\n",
    "        #######################################\n",
    "        \n",
    "        # devolvemos a cero las gradientes\n",
    "        dis_optim.zero_grad()   #####\n",
    "        \n",
    "        # fake_noise: nuevo vector de ruido para el batch de datos\n",
    "        fake_noise = noise_generator(cur_batch_size, dim_z, device=device) ####\n",
    "        \n",
    "        # Introducimos el tensor de ruido al generador\n",
    "        fake = anime_gen(fake_noise)\n",
    "        \n",
    "        # Obtenemos la predicción del discriminador de los datos falsos\n",
    "        ###   D(G(z))\n",
    "        disc_fake_pred = anime_dis(fake.detach())\n",
    "        #Obs: Detach <> ¿puntero al tensor?\n",
    "        \n",
    "        # Obtenemos la predicción del discriminador de los datos reales\n",
    "        ###   D(G(z))\n",
    "        disc_real_pred = anime_dis(real)\n",
    "        \n",
    "        # Obtenemos los valores de pérdida al evaluar los datos falsos\n",
    "        # Básicamente etiqueta a la distribución de estos datos como falsa\n",
    "        # al darles como valor 0\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        \n",
    "        # Obtenemos los valores de pérdida al evaluar los datos reales\n",
    "        # Básicamente etiqueta a la distribución de estos datos como verdadero\n",
    "        # al darles como valor 1\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        \n",
    "        # Obtenemos la media general de las pérdidas en esta iteración\n",
    "        disc_loss = (disc_fake_loss.float() + disc_real_loss.float()) / 2\n",
    "\n",
    "        # Obtenemos el promedio ponderado de la pérdida del \n",
    "        # discriminador \n",
    "        mean_discriminator_loss += disc_loss.item()/display_step\n",
    "        \n",
    "        \n",
    "        # Actualizamos gradientes\n",
    "        # retain_graph=True permite mantener la pérdida durante el proceso\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Actualizamos el optimizador\n",
    "        dis_optim.step()\n",
    "\n",
    "        \n",
    "        ###################################\n",
    "        ##   Actualizamos el generador   ##\n",
    "        ###################################\n",
    "        \n",
    "        # devolvemos a cero las gradientes\n",
    "        gen_optim.zero_grad()\n",
    "        \n",
    "        # Creamos un nuevo tensor de ruido para el generador\n",
    "        fake_noise_2 = noise_generator(cur_batch_size, dim_z, device=device)\n",
    "        \n",
    "        # Obtenemos el resultado de evaluar el tensor en el modelo\n",
    "        fake_2 = anime_gen(fake_noise_2)\n",
    "        \n",
    "        # Obtenemos nuevamente la predicción del Discriminador\n",
    "        disc_fake_pred = anime_dis(fake_2)\n",
    "        \n",
    "        # Obtenemos la evaluación de la función de pérdida \n",
    "        # Buscamos etiquetar nuestros datos falsos como verdaderos\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        \n",
    "        # Actualizamos gradientes de la función de pérdida del generador\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        # Actualizamos el optimizador\n",
    "        gen_optim.step()\n",
    "        \n",
    "        \n",
    "        # Obtenemos el promedio ponderado de la pérdida del \n",
    "        # generador \n",
    "        mean_generator_loss += gen_loss.item()/ display_step\n",
    "\n",
    "        # Guardamos los valores de pérdida para su ploteo\n",
    "        G_losses.append(gen_loss.item())\n",
    "        D_losses.append(disc_loss.item())\n",
    "        \n",
    "        ## \n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            display_losses(cur_step, display_step, G_losses, D_losses)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n",
    "        \n",
    "    if epoch % 25 == 0:\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': anime_gen.state_dict(),\n",
    "                'optimizer_state_dict': gen_optim.state_dict(),\n",
    "                'loss': G_losses,\n",
    "                }, 'generator_anime_G4.pt')\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': anime_dis.state_dict(),\n",
    "                'optimizer_state_dict': dis_optim.state_dict(),\n",
    "                'loss': D_losses,\n",
    "                }, 'discriminator_anime_G4.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
