{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda2e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b65ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# Este comando nos permitirá realizar un seguimiento de la depuración ocurrida durante el uso de CUDA\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as dtst\n",
    "from torch import optim\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Retiramos los mensajes de alerta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Inicializamos las semillas de los valores aleatorios\n",
    "random.seed(99)\n",
    "torch.manual_seed(99)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2c599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21fbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b309f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './images'\n",
    "\n",
    "# Tamaño que deseamos que tengan las imágenes\n",
    "image_size = 128\n",
    "# Tamaño del lote de imágenes\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "dsimgs = dtst.ImageFolder(\n",
    "    root=data_folder,\n",
    "    transform=transforms.Compose([\n",
    "        # Se usa el resize en caso no todas las imágenes de entrada tengan el tamaño de 128px\n",
    "        transforms.Resize(image_size),\n",
    "        # CenterCrop busca recortar la imagen en caso sea muy grande al tamaño dado\n",
    "        transforms.CenterCrop(image_size),\n",
    "        # ToTensor convierte finalmente la imagen a tensor\n",
    "        transforms.ToTensor()\n",
    "        # Normalize permite la normalización de la información\n",
    "        # El problema encontrado es que necesitamos hallar la desviación estandar\n",
    "        # media de toda la información para realizar una correcta normalización\n",
    "        \n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dbb3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 41512\n",
       "    Root location: ./images\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               CenterCrop(size=(128, 128))\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4cd3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_loader = DataLoader(dsimgs,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1,\n",
    "                       drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1115930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r=[]\n",
    "list_g=[]\n",
    "list_b=[]\n",
    "\n",
    "for real, _ in dt_loader:\n",
    "#     print(real[63].shape)\n",
    "    list_r.append(real[0,:,:].mean().float())   \n",
    "    list_g.append(real[1,:,:].mean().float())   \n",
    "    list_b.append(real[2,:,:].mean().float())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e365e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_d=[]\n",
    "list_g_d=[]\n",
    "list_b_d=[]\n",
    "\n",
    "for real, _ in dt_loader:\n",
    "#     print(real[63].shape)\n",
    "    i=0\n",
    "    list_r_d.append((real[0,:,:]**2).mean().float()-list_r[i]**2)   \n",
    "    list_g_d.append((real[1,:,:]**2).mean().float()-list_g[i]**2)   \n",
    "    list_b_d.append((real[2,:,:]**2).mean().float()-list_b[i]**2)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51fc09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n",
      "tensor(0.6134)\n",
      "tensor(0.6145)\n",
      "tensor(0.6188)\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print(len(list_b))\n",
    "\n",
    "print(torch.mean(torch.stack(list_r)))\n",
    "print(torch.mean(torch.stack(list_g)))\n",
    "print(torch.mean(torch.stack(list_b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd01cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5238), tensor(0.7366), tensor(0.6058), tensor(0.6941), tensor(0.8079), tensor(0.5185), tensor(0.4516), tensor(0.4548), tensor(0.5160), tensor(0.4713), tensor(0.5938), tensor(0.5201), tensor(0.6375), tensor(0.4173), tensor(0.6818), tensor(0.6083), tensor(0.5658), tensor(0.5390), tensor(0.5908), tensor(0.5474), tensor(0.6639), tensor(0.5409), tensor(0.5807), tensor(0.7043), tensor(0.7000), tensor(0.6063), tensor(0.6788), tensor(0.7574), tensor(0.5423), tensor(0.6287), tensor(0.7483), tensor(0.6027), tensor(0.7550), tensor(0.7950), tensor(0.7495), tensor(0.6141), tensor(0.5673), tensor(0.6711), tensor(0.5256), tensor(0.7362), tensor(0.6483), tensor(0.7367), tensor(0.6952), tensor(0.5330), tensor(0.4871), tensor(0.5002), tensor(0.4232), tensor(0.5941), tensor(0.6844), tensor(0.5033), tensor(0.6272), tensor(0.4484), tensor(0.4296), tensor(0.7862), tensor(0.7557), tensor(0.4173), tensor(0.7050), tensor(0.4683), tensor(0.6340), tensor(0.7349), tensor(0.5363), tensor(0.5582), tensor(0.4536), tensor(0.7313), tensor(0.5451), tensor(0.6339), tensor(0.7584), tensor(0.5590), tensor(0.5658), tensor(0.4290), tensor(0.5736), tensor(0.6010), tensor(0.6512), tensor(0.6169), tensor(0.5031), tensor(0.4439), tensor(0.8090), tensor(0.7646), tensor(0.6494), tensor(0.5308), tensor(0.5998), tensor(0.6014), tensor(0.6525), tensor(0.4730), tensor(0.5573), tensor(0.4616), tensor(0.3371), tensor(0.4902), tensor(0.7768), tensor(0.5163), tensor(0.4624), tensor(0.5860), tensor(0.5528), tensor(0.6029), tensor(0.7275), tensor(0.5470), tensor(0.6350), tensor(0.5874), tensor(0.6849), tensor(0.5858), tensor(0.5742), tensor(0.6115), tensor(0.7228), tensor(0.6370), tensor(0.6792), tensor(0.5350), tensor(0.6526), tensor(0.7567), tensor(0.6822), tensor(0.7173), tensor(0.6827), tensor(0.5906), tensor(0.4927), tensor(0.5904), tensor(0.8401), tensor(0.7132), tensor(0.4483), tensor(0.4432), tensor(0.6161), tensor(0.7563), tensor(0.5367), tensor(0.4836), tensor(0.7786), tensor(0.6029), tensor(0.7616), tensor(0.8271), tensor(0.4075), tensor(0.4342), tensor(0.6050), tensor(0.3955), tensor(0.5074), tensor(0.7191), tensor(0.7304), tensor(0.5574), tensor(0.6591), tensor(0.6928), tensor(0.6038), tensor(0.5317), tensor(0.7617), tensor(0.6434), tensor(0.4933), tensor(0.5461), tensor(0.6692), tensor(0.6269), tensor(0.9617), tensor(0.7652), tensor(0.7867), tensor(0.6301), tensor(0.4529), tensor(0.6922), tensor(0.5472), tensor(0.5695), tensor(0.5084), tensor(0.5545), tensor(0.5665), tensor(0.5357), tensor(0.5572), tensor(0.4976), tensor(0.4510), tensor(0.5368), tensor(0.7300), tensor(0.6232), tensor(0.6302), tensor(0.4416), tensor(0.6115), tensor(0.5533), tensor(0.5177), tensor(0.6927), tensor(0.7148), tensor(0.5127), tensor(0.7417), tensor(0.7121), tensor(0.6817), tensor(0.5274), tensor(0.5214), tensor(0.4555), tensor(0.5587), tensor(0.6469), tensor(0.8165), tensor(0.5616), tensor(0.5608), tensor(0.3903), tensor(0.6266), tensor(0.7717), tensor(0.5518), tensor(0.6293), tensor(0.5044), tensor(0.5832), tensor(0.6483), tensor(0.4605), tensor(0.5844), tensor(0.5128), tensor(0.4799), tensor(0.4766), tensor(0.6135), tensor(0.7984), tensor(0.5923), tensor(0.7516), tensor(0.6132), tensor(0.6033), tensor(0.6810), tensor(0.7616), tensor(0.4088), tensor(0.6272), tensor(0.8089), tensor(0.8072), tensor(0.5842), tensor(0.4987), tensor(0.4739), tensor(0.7332), tensor(0.6091), tensor(0.6447), tensor(0.7635), tensor(0.6944), tensor(0.4644), tensor(0.7157), tensor(0.7386), tensor(0.7277), tensor(0.7307), tensor(0.7559), tensor(0.5721), tensor(0.4460), tensor(0.6288), tensor(0.7485), tensor(0.6261), tensor(0.6906), tensor(0.6923), tensor(0.5838), tensor(0.5032), tensor(0.7920), tensor(0.7331), tensor(0.6440), tensor(0.3590), tensor(0.7073), tensor(0.3968), tensor(0.5450), tensor(0.4425), tensor(0.6221), tensor(0.6254), tensor(0.5773), tensor(0.7726), tensor(0.6917), tensor(0.4579), tensor(0.7583), tensor(0.6378), tensor(0.6526), tensor(0.6591), tensor(0.6101), tensor(0.4121), tensor(0.5222), tensor(0.5371), tensor(0.6026), tensor(0.5760), tensor(0.5650), tensor(0.3972), tensor(0.7821), tensor(0.4608), tensor(0.6065), tensor(0.4607), tensor(0.6393), tensor(0.4182), tensor(0.4712), tensor(0.4052), tensor(0.7696), tensor(0.7372), tensor(0.6653), tensor(0.4975), tensor(0.6512), tensor(0.5371), tensor(0.4273), tensor(0.7433), tensor(0.6776), tensor(0.6945), tensor(0.7736), tensor(0.7362), tensor(0.5198), tensor(0.5330), tensor(0.7459), tensor(0.6023), tensor(0.6942), tensor(0.5373), tensor(0.3761), tensor(0.5976), tensor(0.6892), tensor(0.7626), tensor(0.7641), tensor(0.5465), tensor(0.6795), tensor(0.5029), tensor(0.4858), tensor(0.7008), tensor(0.5419), tensor(0.5583), tensor(0.6496), tensor(0.5078), tensor(0.6817), tensor(0.5791), tensor(0.6725), tensor(0.6054), tensor(0.6900), tensor(0.6850), tensor(0.7260), tensor(0.5827), tensor(0.5425), tensor(0.5311), tensor(0.7151), tensor(0.5130), tensor(0.4741), tensor(0.4976), tensor(0.4857), tensor(0.3843), tensor(0.6724), tensor(0.4793), tensor(0.6029), tensor(0.5000), tensor(0.6309), tensor(0.5626), tensor(0.5492), tensor(0.6701), tensor(0.6035), tensor(0.6060), tensor(0.7112), tensor(0.6817), tensor(0.6694), tensor(0.6294), tensor(0.6457), tensor(0.8665), tensor(0.4915), tensor(0.7490), tensor(0.6693), tensor(0.7128), tensor(0.7509), tensor(0.5399), tensor(0.4007), tensor(0.4354), tensor(0.7316), tensor(0.5476), tensor(0.6840), tensor(0.5227), tensor(0.6010), tensor(0.5542), tensor(0.7022), tensor(0.6290), tensor(0.6850), tensor(0.6265), tensor(0.5869), tensor(0.8096), tensor(0.4070), tensor(0.6373), tensor(0.5959), tensor(0.6963), tensor(0.6349), tensor(0.5845), tensor(0.6381), tensor(0.8409), tensor(0.6244), tensor(0.6845), tensor(0.8052), tensor(0.7876), tensor(0.4967), tensor(0.6535), tensor(0.6497), tensor(0.4985), tensor(0.8132), tensor(0.5126), tensor(0.4330), tensor(0.5734), tensor(0.6538), tensor(0.6349), tensor(0.7133), tensor(0.6329), tensor(0.4717), tensor(0.7329), tensor(0.5438), tensor(0.6510), tensor(0.5128), tensor(0.5822), tensor(0.5851), tensor(0.6564), tensor(0.6846), tensor(0.4633), tensor(0.6392), tensor(0.5139), tensor(0.5014), tensor(0.6410), tensor(0.6150), tensor(0.7049), tensor(0.6487), tensor(0.4420), tensor(0.7678), tensor(0.4313), tensor(0.6205), tensor(0.6856), tensor(0.5961), tensor(0.4973), tensor(0.5813), tensor(0.7717), tensor(0.8644), tensor(0.5348), tensor(0.5939), tensor(0.7347), tensor(0.7670), tensor(0.7522), tensor(0.7227), tensor(0.6858), tensor(0.5529), tensor(0.6107), tensor(0.6243), tensor(0.4347), tensor(0.7590), tensor(0.6083), tensor(0.5847), tensor(0.7956), tensor(0.5470), tensor(0.5701), tensor(0.5293), tensor(0.7746), tensor(0.6218), tensor(0.7467), tensor(0.6316), tensor(0.4870), tensor(0.6569), tensor(0.5539), tensor(0.7222), tensor(0.2958), tensor(0.7765), tensor(0.7641), tensor(0.8666), tensor(0.5690), tensor(0.6463), tensor(0.6680), tensor(0.6782), tensor(0.6329), tensor(0.5936), tensor(0.5786), tensor(0.7960), tensor(0.5456), tensor(0.6133), tensor(0.6165), tensor(0.8097), tensor(0.7765), tensor(0.6468), tensor(0.4683), tensor(0.8259), tensor(0.4766), tensor(0.5548), tensor(0.5530), tensor(0.6183), tensor(0.5312), tensor(0.6504), tensor(0.6594), tensor(0.7754), tensor(0.6267), tensor(0.7185), tensor(0.7046), tensor(0.4872), tensor(0.6359), tensor(0.5810), tensor(0.5887), tensor(0.4003), tensor(0.4387), tensor(0.6565), tensor(0.6431), tensor(0.5101), tensor(0.5963), tensor(0.5236), tensor(0.5365), tensor(0.7466), tensor(0.5435), tensor(0.7680), tensor(0.7478), tensor(0.6454), tensor(0.7692), tensor(0.6183), tensor(0.5065), tensor(0.6126), tensor(0.6552), tensor(0.5824), tensor(0.6772), tensor(0.5882), tensor(0.6440), tensor(0.6052), tensor(0.5958), tensor(0.7022), tensor(0.6400), tensor(0.7965), tensor(0.7115), tensor(0.5365), tensor(0.5457), tensor(0.5582), tensor(0.3756), tensor(0.8083), tensor(0.6698), tensor(0.4554), tensor(0.6232), tensor(0.3738), tensor(0.6123), tensor(0.5605), tensor(0.5826), tensor(0.7383), tensor(0.6169), tensor(0.7080), tensor(0.5537), tensor(0.4325), tensor(0.4908), tensor(0.4826), tensor(0.4235), tensor(0.6648), tensor(0.6130), tensor(0.5741), tensor(0.7567), tensor(0.5494), tensor(0.6343), tensor(0.5999), tensor(0.7041), tensor(0.6044), tensor(0.6075), tensor(0.6807), tensor(0.5718), tensor(0.7890), tensor(0.4534), tensor(0.6971), tensor(0.6081), tensor(0.4752), tensor(0.6595), tensor(0.6429), tensor(0.7923), tensor(0.7228), tensor(0.6182), tensor(0.4783), tensor(0.4736), tensor(0.6503), tensor(0.4986), tensor(0.5336), tensor(0.6423), tensor(0.5751), tensor(0.6942), tensor(0.7013), tensor(0.5139), tensor(0.5648), tensor(0.5470), tensor(0.6063), tensor(0.8303), tensor(0.5673), tensor(0.5602), tensor(0.7625), tensor(0.6326), tensor(0.7435), tensor(0.5689), tensor(0.5822), tensor(0.7546), tensor(0.5550), tensor(0.6260), tensor(0.6138), tensor(0.6652), tensor(0.6440), tensor(0.5066), tensor(0.6905), tensor(0.4856), tensor(0.6501), tensor(0.4864), tensor(0.7771), tensor(0.7710), tensor(0.6154), tensor(0.4655), tensor(0.6265), tensor(0.6987), tensor(0.5142), tensor(0.4989), tensor(0.6639), tensor(0.7216), tensor(0.6011), tensor(0.4565), tensor(0.5448), tensor(0.6661), tensor(0.5870), tensor(0.4245), tensor(0.7952), tensor(0.7000), tensor(0.5911), tensor(0.7366), tensor(0.7594), tensor(0.4989), tensor(0.7616), tensor(0.6246), tensor(0.6773), tensor(0.7423), tensor(0.5824), tensor(0.5699), tensor(0.5314), tensor(0.5022), tensor(0.5439), tensor(0.5948), tensor(0.7278), tensor(0.5582), tensor(0.5913), tensor(0.5465), tensor(0.7044), tensor(0.6075), tensor(0.4904), tensor(0.7161), tensor(0.6160), tensor(0.6802), tensor(0.6215), tensor(0.5762), tensor(0.6221), tensor(0.5663), tensor(0.7582), tensor(0.3918), tensor(0.4772), tensor(0.5267), tensor(0.7816), tensor(0.6237), tensor(0.7793), tensor(0.5412), tensor(0.6827), tensor(0.4920), tensor(0.7849), tensor(0.5225), tensor(0.5431), tensor(0.6244), tensor(0.5189), tensor(0.8160), tensor(0.7807), tensor(0.5603), tensor(0.5178), tensor(0.7913), tensor(0.7174), tensor(0.4697), tensor(0.6093), tensor(0.7136), tensor(0.5612), tensor(0.8102), tensor(0.7668), tensor(0.6099), tensor(0.6008), tensor(0.5944), tensor(0.7299), tensor(0.4939), tensor(0.5910), tensor(0.6431), tensor(0.2815), tensor(0.3503), tensor(0.7638), tensor(0.7626), tensor(0.6612), tensor(0.7504), tensor(0.6322)]\n"
     ]
    }
   ],
   "source": [
    "print(list_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afb7c7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4335)\n",
      "tensor(0.4493)\n",
      "tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.sqrt(torch.mean(torch.stack(list_r_d))))\n",
    "print(torch.sqrt(torch.mean(torch.stack(list_g_d))))\n",
    "print(torch.sqrt(torch.mean(torch.stack(list_b_d))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ee8cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_d2=[]\n",
    "list_g_d2=[]\n",
    "list_b_d2=[]\n",
    "\n",
    "for real, _ in dt_loader:\n",
    "#     print(real[63].shape)\n",
    "    list_r_d2.append(torch.std_mean(real[0,:,:]))   \n",
    "    list_g_d2.append(torch.std_mean(real[1,:,:]))   \n",
    "    list_b_d2.append(torch.std_mean(real[2,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf9f01d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.3094), tensor(0.3898))\n",
      "(tensor(0.2849), tensor(0.4702))\n",
      "(tensor(0.3118), tensor(0.5212))\n",
      "(tensor(0.3109), tensor(0.5805))\n",
      "(tensor(0.2081), tensor(0.7235))\n",
      "(tensor(0.2527), tensor(0.6668))\n",
      "(tensor(0.2589), tensor(0.5799))\n",
      "(tensor(0.2454), tensor(0.6128))\n",
      "(tensor(0.2403), tensor(0.6251))\n",
      "(tensor(0.2509), tensor(0.7247))\n",
      "(tensor(0.2461), tensor(0.4582))\n",
      "(tensor(0.2843), tensor(0.4239))\n",
      "(tensor(0.2842), tensor(0.5839))\n",
      "(tensor(0.2969), tensor(0.7101))\n",
      "(tensor(0.3081), tensor(0.6336))\n",
      "(tensor(0.2831), tensor(0.5150))\n",
      "(tensor(0.2820), tensor(0.4948))\n",
      "(tensor(0.2300), tensor(0.7510))\n",
      "(tensor(0.2626), tensor(0.6364))\n",
      "(tensor(0.2509), tensor(0.6792))\n",
      "(tensor(0.2662), tensor(0.6484))\n",
      "(tensor(0.2530), tensor(0.6104))\n",
      "(tensor(0.2245), tensor(0.7506))\n",
      "(tensor(0.2445), tensor(0.7000))\n",
      "(tensor(0.1879), tensor(0.8157))\n",
      "(tensor(0.2861), tensor(0.5911))\n",
      "(tensor(0.2770), tensor(0.5958))\n",
      "(tensor(0.3133), tensor(0.5812))\n",
      "(tensor(0.2987), tensor(0.4562))\n",
      "(tensor(0.3222), tensor(0.4661))\n",
      "(tensor(0.2324), tensor(0.6296))\n",
      "(tensor(0.3105), tensor(0.6502))\n",
      "(tensor(0.2321), tensor(0.6950))\n",
      "(tensor(0.2258), tensor(0.6394))\n",
      "(tensor(0.2200), tensor(0.7709))\n",
      "(tensor(0.3228), tensor(0.5445))\n",
      "(tensor(0.2134), tensor(0.7695))\n",
      "(tensor(0.2474), tensor(0.6311))\n",
      "(tensor(0.2701), tensor(0.5895))\n",
      "(tensor(0.2995), tensor(0.4659))\n",
      "(tensor(0.3389), tensor(0.4755))\n",
      "(tensor(0.2680), tensor(0.5428))\n",
      "(tensor(0.2040), tensor(0.6507))\n",
      "(tensor(0.3352), tensor(0.4016))\n",
      "(tensor(0.2569), tensor(0.6337))\n",
      "(tensor(0.3094), tensor(0.5100))\n",
      "(tensor(0.1842), tensor(0.7881))\n",
      "(tensor(0.2691), tensor(0.6514))\n",
      "(tensor(0.2629), tensor(0.4775))\n",
      "(tensor(0.3242), tensor(0.6584))\n",
      "(tensor(0.1854), tensor(0.7279))\n",
      "(tensor(0.2473), tensor(0.5477))\n",
      "(tensor(0.2630), tensor(0.5784))\n",
      "(tensor(0.2885), tensor(0.4323))\n",
      "(tensor(0.2549), tensor(0.6752))\n",
      "(tensor(0.1985), tensor(0.8091))\n",
      "(tensor(0.2826), tensor(0.5738))\n",
      "(tensor(0.2716), tensor(0.5972))\n",
      "(tensor(0.2009), tensor(0.7448))\n",
      "(tensor(0.2041), tensor(0.7310))\n",
      "(tensor(0.1863), tensor(0.7921))\n",
      "(tensor(0.2431), tensor(0.6882))\n",
      "(tensor(0.3025), tensor(0.3834))\n",
      "(tensor(0.2714), tensor(0.5773))\n",
      "(tensor(0.2830), tensor(0.5513))\n",
      "(tensor(0.2073), tensor(0.7339))\n",
      "(tensor(0.2126), tensor(0.7876))\n",
      "(tensor(0.3091), tensor(0.4843))\n",
      "(tensor(0.2173), tensor(0.7394))\n",
      "(tensor(0.3354), tensor(0.4766))\n",
      "(tensor(0.2930), tensor(0.5396))\n",
      "(tensor(0.3420), tensor(0.4826))\n",
      "(tensor(0.2900), tensor(0.5456))\n",
      "(tensor(0.3246), tensor(0.3212))\n",
      "(tensor(0.3118), tensor(0.4847))\n",
      "(tensor(0.2415), tensor(0.6813))\n",
      "(tensor(0.3203), tensor(0.5009))\n",
      "(tensor(0.3052), tensor(0.5342))\n",
      "(tensor(0.2743), tensor(0.6866))\n",
      "(tensor(0.2463), tensor(0.7308))\n",
      "(tensor(0.3381), tensor(0.4480))\n",
      "(tensor(0.2787), tensor(0.6514))\n",
      "(tensor(0.2969), tensor(0.5562))\n",
      "(tensor(0.2305), tensor(0.6801))\n",
      "(tensor(0.2593), tensor(0.6354))\n",
      "(tensor(0.2483), tensor(0.6710))\n",
      "(tensor(0.3142), tensor(0.4117))\n",
      "(tensor(0.3296), tensor(0.5132))\n",
      "(tensor(0.2975), tensor(0.5081))\n",
      "(tensor(0.2836), tensor(0.6239))\n",
      "(tensor(0.2808), tensor(0.6458))\n",
      "(tensor(0.2360), tensor(0.7223))\n",
      "(tensor(0.3173), tensor(0.4302))\n",
      "(tensor(0.3316), tensor(0.5012))\n",
      "(tensor(0.2804), tensor(0.6844))\n",
      "(tensor(0.3729), tensor(0.4636))\n",
      "(tensor(0.2842), tensor(0.6532))\n",
      "(tensor(0.2424), tensor(0.6873))\n",
      "(tensor(0.2689), tensor(0.6912))\n",
      "(tensor(0.3026), tensor(0.4742))\n",
      "(tensor(0.3010), tensor(0.4343))\n",
      "(tensor(0.2928), tensor(0.5788))\n",
      "(tensor(0.3113), tensor(0.5721))\n",
      "(tensor(0.3000), tensor(0.4888))\n",
      "(tensor(0.2525), tensor(0.4603))\n",
      "(tensor(0.2773), tensor(0.5596))\n",
      "(tensor(0.3597), tensor(0.4953))\n",
      "(tensor(0.2558), tensor(0.6393))\n",
      "(tensor(0.2349), tensor(0.5810))\n",
      "(tensor(0.3183), tensor(0.5610))\n",
      "(tensor(0.3526), tensor(0.4843))\n",
      "(tensor(0.2982), tensor(0.4654))\n",
      "(tensor(0.3235), tensor(0.4073))\n",
      "(tensor(0.2472), tensor(0.6569))\n",
      "(tensor(0.3017), tensor(0.5914))\n",
      "(tensor(0.3042), tensor(0.5666))\n",
      "(tensor(0.3042), tensor(0.5924))\n",
      "(tensor(0.2621), tensor(0.4853))\n",
      "(tensor(0.2996), tensor(0.4794))\n",
      "(tensor(0.2825), tensor(0.5452))\n",
      "(tensor(0.3081), tensor(0.4895))\n",
      "(tensor(0.3179), tensor(0.6005))\n",
      "(tensor(0.3039), tensor(0.5092))\n",
      "(tensor(0.2218), tensor(0.7292))\n",
      "(tensor(0.2641), tensor(0.6777))\n",
      "(tensor(0.1760), tensor(0.8095))\n",
      "(tensor(0.2547), tensor(0.6005))\n",
      "(tensor(0.2805), tensor(0.5235))\n",
      "(tensor(0.1954), tensor(0.7621))\n",
      "(tensor(0.2764), tensor(0.6680))\n",
      "(tensor(0.2723), tensor(0.5059))\n",
      "(tensor(0.3518), tensor(0.5335))\n",
      "(tensor(0.2824), tensor(0.5437))\n",
      "(tensor(0.2959), tensor(0.4565))\n",
      "(tensor(0.2325), tensor(0.6255))\n",
      "(tensor(0.2880), tensor(0.5183))\n",
      "(tensor(0.2577), tensor(0.4932))\n",
      "(tensor(0.1993), tensor(0.7346))\n",
      "(tensor(0.2312), tensor(0.7140))\n",
      "(tensor(0.2691), tensor(0.6560))\n",
      "(tensor(0.2834), tensor(0.5910))\n",
      "(tensor(0.3326), tensor(0.4876))\n",
      "(tensor(0.2846), tensor(0.4980))\n",
      "(tensor(0.1718), tensor(0.8288))\n",
      "(tensor(0.3196), tensor(0.4094))\n",
      "(tensor(0.2772), tensor(0.5852))\n",
      "(tensor(0.2985), tensor(0.5558))\n",
      "(tensor(0.3291), tensor(0.5456))\n",
      "(tensor(0.2478), tensor(0.5667))\n",
      "(tensor(0.2341), tensor(0.7500))\n",
      "(tensor(0.2923), tensor(0.5957))\n",
      "(tensor(0.2426), tensor(0.6231))\n",
      "(tensor(0.2871), tensor(0.6024))\n",
      "(tensor(0.2723), tensor(0.5529))\n",
      "(tensor(0.2388), tensor(0.6708))\n",
      "(tensor(0.2613), tensor(0.6954))\n",
      "(tensor(0.2997), tensor(0.5756))\n",
      "(tensor(0.3133), tensor(0.5834))\n",
      "(tensor(0.2542), tensor(0.7383))\n",
      "(tensor(0.2465), tensor(0.6382))\n",
      "(tensor(0.3047), tensor(0.5778))\n",
      "(tensor(0.1902), tensor(0.8016))\n",
      "(tensor(0.3390), tensor(0.5894))\n",
      "(tensor(0.2535), tensor(0.6229))\n",
      "(tensor(0.2861), tensor(0.6760))\n",
      "(tensor(0.2572), tensor(0.6823))\n",
      "(tensor(0.1926), tensor(0.7377))\n",
      "(tensor(0.2252), tensor(0.7227))\n",
      "(tensor(0.2724), tensor(0.6002))\n",
      "(tensor(0.2249), tensor(0.7121))\n",
      "(tensor(0.2946), tensor(0.3999))\n",
      "(tensor(0.2508), tensor(0.7289))\n",
      "(tensor(0.2385), tensor(0.7816))\n",
      "(tensor(0.2651), tensor(0.6011))\n",
      "(tensor(0.2797), tensor(0.6560))\n",
      "(tensor(0.2449), tensor(0.7266))\n",
      "(tensor(0.2121), tensor(0.7196))\n",
      "(tensor(0.1516), tensor(0.8389))\n",
      "(tensor(0.2509), tensor(0.5201))\n",
      "(tensor(0.3058), tensor(0.5857))\n",
      "(tensor(0.2707), tensor(0.5886))\n",
      "(tensor(0.2320), tensor(0.6729))\n",
      "(tensor(0.3100), tensor(0.4120))\n",
      "(tensor(0.2743), tensor(0.4378))\n",
      "(tensor(0.3124), tensor(0.4177))\n",
      "(tensor(0.2888), tensor(0.5378))\n",
      "(tensor(0.1810), tensor(0.8013))\n",
      "(tensor(0.3076), tensor(0.5459))\n",
      "(tensor(0.3084), tensor(0.5246))\n",
      "(tensor(0.2109), tensor(0.7764))\n",
      "(tensor(0.2855), tensor(0.6778))\n",
      "(tensor(0.2752), tensor(0.6542))\n",
      "(tensor(0.2175), tensor(0.7562))\n",
      "(tensor(0.1902), tensor(0.7834))\n",
      "(tensor(0.2717), tensor(0.6586))\n",
      "(tensor(0.2841), tensor(0.7179))\n",
      "(tensor(0.1865), tensor(0.7488))\n",
      "(tensor(0.2915), tensor(0.5873))\n",
      "(tensor(0.2203), tensor(0.7440))\n",
      "(tensor(0.2342), tensor(0.7298))\n",
      "(tensor(0.3143), tensor(0.6410))\n",
      "(tensor(0.2661), tensor(0.4438))\n",
      "(tensor(0.3110), tensor(0.5335))\n",
      "(tensor(0.2199), tensor(0.7243))\n",
      "(tensor(0.2466), tensor(0.6996))\n",
      "(tensor(0.3031), tensor(0.5232))\n",
      "(tensor(0.2594), tensor(0.5495))\n",
      "(tensor(0.2104), tensor(0.7413))\n",
      "(tensor(0.2313), tensor(0.6106))\n",
      "(tensor(0.2495), tensor(0.6204))\n",
      "(tensor(0.2921), tensor(0.6025))\n",
      "(tensor(0.1887), tensor(0.8007))\n",
      "(tensor(0.2270), tensor(0.6435))\n",
      "(tensor(0.3072), tensor(0.6125))\n",
      "(tensor(0.3152), tensor(0.5189))\n",
      "(tensor(0.2156), tensor(0.7548))\n",
      "(tensor(0.2873), tensor(0.5942))\n",
      "(tensor(0.1494), tensor(0.8647))\n",
      "(tensor(0.3169), tensor(0.3954))\n",
      "(tensor(0.2445), tensor(0.7146))\n",
      "(tensor(0.2545), tensor(0.6917))\n",
      "(tensor(0.2631), tensor(0.5856))\n",
      "(tensor(0.2672), tensor(0.6276))\n",
      "(tensor(0.2598), tensor(0.6690))\n",
      "(tensor(0.3058), tensor(0.5373))\n",
      "(tensor(0.2747), tensor(0.6717))\n",
      "(tensor(0.2908), tensor(0.5219))\n",
      "(tensor(0.2359), tensor(0.6679))\n",
      "(tensor(0.2769), tensor(0.4260))\n",
      "(tensor(0.2415), tensor(0.6945))\n",
      "(tensor(0.2598), tensor(0.6870))\n",
      "(tensor(0.2352), tensor(0.5810))\n",
      "(tensor(0.2277), tensor(0.7191))\n",
      "(tensor(0.2464), tensor(0.6868))\n",
      "(tensor(0.1907), tensor(0.7923))\n",
      "(tensor(0.2957), tensor(0.5892))\n",
      "(tensor(0.2782), tensor(0.5047))\n",
      "(tensor(0.2628), tensor(0.6033))\n",
      "(tensor(0.2316), tensor(0.7481))\n",
      "(tensor(0.2712), tensor(0.6251))\n",
      "(tensor(0.2419), tensor(0.7127))\n",
      "(tensor(0.3284), tensor(0.5130))\n",
      "(tensor(0.2836), tensor(0.4946))\n",
      "(tensor(0.3208), tensor(0.6899))\n",
      "(tensor(0.1695), tensor(0.8436))\n",
      "(tensor(0.2457), tensor(0.6905))\n",
      "(tensor(0.3173), tensor(0.5514))\n",
      "(tensor(0.2489), tensor(0.6966))\n",
      "(tensor(0.2500), tensor(0.6833))\n",
      "(tensor(0.3393), tensor(0.4405))\n",
      "(tensor(0.2326), tensor(0.6304))\n",
      "(tensor(0.2327), tensor(0.5964))\n",
      "(tensor(0.2387), tensor(0.6370))\n",
      "(tensor(0.2149), tensor(0.7591))\n",
      "(tensor(0.2897), tensor(0.5120))\n",
      "(tensor(0.2798), tensor(0.5190))\n",
      "(tensor(0.3043), tensor(0.6972))\n",
      "(tensor(0.2740), tensor(0.7087))\n",
      "(tensor(0.2844), tensor(0.5627))\n",
      "(tensor(0.2844), tensor(0.6640))\n",
      "(tensor(0.2475), tensor(0.6987))\n",
      "(tensor(0.3015), tensor(0.5488))\n",
      "(tensor(0.2497), tensor(0.7198))\n",
      "(tensor(0.3046), tensor(0.4857))\n",
      "(tensor(0.2118), tensor(0.6623))\n",
      "(tensor(0.3131), tensor(0.5955))\n",
      "(tensor(0.2277), tensor(0.6342))\n",
      "(tensor(0.3088), tensor(0.5048))\n",
      "(tensor(0.3024), tensor(0.5650))\n",
      "(tensor(0.2441), tensor(0.6723))\n",
      "(tensor(0.2671), tensor(0.6666))\n",
      "(tensor(0.3276), tensor(0.5494))\n",
      "(tensor(0.3101), tensor(0.3609))\n",
      "(tensor(0.2212), tensor(0.7302))\n",
      "(tensor(0.3051), tensor(0.4866))\n",
      "(tensor(0.2484), tensor(0.6237))\n",
      "(tensor(0.2911), tensor(0.6064))\n",
      "(tensor(0.3302), tensor(0.4863))\n",
      "(tensor(0.2584), tensor(0.5882))\n",
      "(tensor(0.2099), tensor(0.7332))\n",
      "(tensor(0.2705), tensor(0.5390))\n",
      "(tensor(0.2297), tensor(0.6947))\n",
      "(tensor(0.2897), tensor(0.5601))\n",
      "(tensor(0.3051), tensor(0.6066))\n",
      "(tensor(0.2834), tensor(0.4489))\n",
      "(tensor(0.2301), tensor(0.7096))\n",
      "(tensor(0.1895), tensor(0.6750))\n",
      "(tensor(0.2784), tensor(0.5711))\n",
      "(tensor(0.2625), tensor(0.6457))\n",
      "(tensor(0.2873), tensor(0.4258))\n",
      "(tensor(0.2693), tensor(0.6110))\n",
      "(tensor(0.3053), tensor(0.4003))\n",
      "(tensor(0.2312), tensor(0.5003))\n",
      "(tensor(0.3062), tensor(0.5777))\n",
      "(tensor(0.2590), tensor(0.5079))\n",
      "(tensor(0.2498), tensor(0.6502))\n",
      "(tensor(0.3190), tensor(0.5034))\n",
      "(tensor(0.2180), tensor(0.7811))\n",
      "(tensor(0.2745), tensor(0.5068))\n",
      "(tensor(0.2674), tensor(0.6455))\n",
      "(tensor(0.1835), tensor(0.8047))\n",
      "(tensor(0.1824), tensor(0.7623))\n",
      "(tensor(0.2622), tensor(0.5700))\n",
      "(tensor(0.3635), tensor(0.5614))\n",
      "(tensor(0.2207), tensor(0.6919))\n",
      "(tensor(0.2076), tensor(0.7463))\n",
      "(tensor(0.1953), tensor(0.7952))\n",
      "(tensor(0.2022), tensor(0.7031))\n",
      "(tensor(0.2840), tensor(0.5363))\n",
      "(tensor(0.2349), tensor(0.6715))\n",
      "(tensor(0.2323), tensor(0.6263))\n",
      "(tensor(0.2492), tensor(0.6384))\n",
      "(tensor(0.2998), tensor(0.5902))\n",
      "(tensor(0.3303), tensor(0.4350))\n",
      "(tensor(0.1506), tensor(0.8097))\n",
      "(tensor(0.2465), tensor(0.5516))\n",
      "(tensor(0.3058), tensor(0.4814))\n",
      "(tensor(0.3332), tensor(0.3994))\n",
      "(tensor(0.3169), tensor(0.5362))\n",
      "(tensor(0.2730), tensor(0.6831))\n",
      "(tensor(0.2700), tensor(0.6498))\n",
      "(tensor(0.3006), tensor(0.4872))\n",
      "(tensor(0.2196), tensor(0.6383))\n",
      "(tensor(0.2321), tensor(0.7793))\n",
      "(tensor(0.2678), tensor(0.5247))\n",
      "(tensor(0.2229), tensor(0.6118))\n",
      "(tensor(0.3101), tensor(0.5324))\n",
      "(tensor(0.2831), tensor(0.5044))\n",
      "(tensor(0.2335), tensor(0.6873))\n",
      "(tensor(0.2385), tensor(0.6972))\n",
      "(tensor(0.2236), tensor(0.7378))\n",
      "(tensor(0.2588), tensor(0.4871))\n",
      "(tensor(0.2569), tensor(0.6486))\n",
      "(tensor(0.3193), tensor(0.4266))\n",
      "(tensor(0.2601), tensor(0.5766))\n",
      "(tensor(0.1888), tensor(0.8100))\n",
      "(tensor(0.2863), tensor(0.6655))\n",
      "(tensor(0.3032), tensor(0.5085))\n",
      "(tensor(0.2293), tensor(0.7154))\n",
      "(tensor(0.2827), tensor(0.5749))\n",
      "(tensor(0.2643), tensor(0.5252))\n",
      "(tensor(0.2690), tensor(0.6880))\n",
      "(tensor(0.2249), tensor(0.6433))\n",
      "(tensor(0.3084), tensor(0.4583))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2989), tensor(0.4077))\n",
      "(tensor(0.2709), tensor(0.7233))\n",
      "(tensor(0.1984), tensor(0.7989))\n",
      "(tensor(0.2506), tensor(0.7074))\n",
      "(tensor(0.2397), tensor(0.5973))\n",
      "(tensor(0.3578), tensor(0.4428))\n",
      "(tensor(0.2555), tensor(0.5953))\n",
      "(tensor(0.1799), tensor(0.7663))\n",
      "(tensor(0.2145), tensor(0.7419))\n",
      "(tensor(0.1763), tensor(0.8167))\n",
      "(tensor(0.3114), tensor(0.4555))\n",
      "(tensor(0.2006), tensor(0.7523))\n",
      "(tensor(0.2645), tensor(0.5025))\n",
      "(tensor(0.2786), tensor(0.5763))\n",
      "(tensor(0.2633), tensor(0.6602))\n",
      "(tensor(0.3134), tensor(0.5943))\n",
      "(tensor(0.2377), tensor(0.7930))\n",
      "(tensor(0.2640), tensor(0.7130))\n",
      "(tensor(0.2138), tensor(0.7393))\n",
      "(tensor(0.2238), tensor(0.6481))\n",
      "(tensor(0.3157), tensor(0.4432))\n",
      "(tensor(0.2913), tensor(0.3846))\n",
      "(tensor(0.3495), tensor(0.5367))\n",
      "(tensor(0.2338), tensor(0.5992))\n",
      "(tensor(0.2763), tensor(0.6294))\n",
      "(tensor(0.2735), tensor(0.5913))\n",
      "(tensor(0.3095), tensor(0.5986))\n",
      "(tensor(0.1902), tensor(0.7031))\n",
      "(tensor(0.3165), tensor(0.5788))\n",
      "(tensor(0.2129), tensor(0.7345))\n",
      "(tensor(0.2057), tensor(0.7589))\n",
      "(tensor(0.3136), tensor(0.4679))\n",
      "(tensor(0.2721), tensor(0.5463))\n",
      "(tensor(0.3414), tensor(0.3979))\n",
      "(tensor(0.2403), tensor(0.6918))\n",
      "(tensor(0.3110), tensor(0.5083))\n",
      "(tensor(0.1941), tensor(0.7754))\n",
      "(tensor(0.2846), tensor(0.4791))\n",
      "(tensor(0.2094), tensor(0.7375))\n",
      "(tensor(0.2877), tensor(0.6309))\n",
      "(tensor(0.2106), tensor(0.7208))\n",
      "(tensor(0.2620), tensor(0.5954))\n",
      "(tensor(0.1975), tensor(0.7833))\n",
      "(tensor(0.2291), tensor(0.7616))\n",
      "(tensor(0.3575), tensor(0.4866))\n",
      "(tensor(0.2603), tensor(0.5975))\n",
      "(tensor(0.2181), tensor(0.7785))\n",
      "(tensor(0.2914), tensor(0.5937))\n",
      "(tensor(0.3090), tensor(0.4928))\n",
      "(tensor(0.2938), tensor(0.4914))\n",
      "(tensor(0.1870), tensor(0.7562))\n",
      "(tensor(0.2797), tensor(0.6508))\n",
      "(tensor(0.1937), tensor(0.8123))\n",
      "(tensor(0.2873), tensor(0.5386))\n",
      "(tensor(0.2107), tensor(0.8055))\n",
      "(tensor(0.3179), tensor(0.5044))\n",
      "(tensor(0.2625), tensor(0.6763))\n",
      "(tensor(0.2665), tensor(0.5391))\n",
      "(tensor(0.2819), tensor(0.7006))\n",
      "(tensor(0.2818), tensor(0.3683))\n",
      "(tensor(0.2099), tensor(0.7641))\n",
      "(tensor(0.2919), tensor(0.5518))\n",
      "(tensor(0.2776), tensor(0.5427))\n",
      "(tensor(0.3019), tensor(0.5923))\n",
      "(tensor(0.2803), tensor(0.6149))\n",
      "(tensor(0.2721), tensor(0.5344))\n",
      "(tensor(0.2804), tensor(0.6222))\n",
      "(tensor(0.2517), tensor(0.5582))\n",
      "(tensor(0.2594), tensor(0.5999))\n",
      "(tensor(0.2840), tensor(0.6062))\n",
      "(tensor(0.3139), tensor(0.4548))\n",
      "(tensor(0.2370), tensor(0.7564))\n",
      "(tensor(0.2946), tensor(0.5615))\n",
      "(tensor(0.3281), tensor(0.5232))\n",
      "(tensor(0.3056), tensor(0.5682))\n",
      "(tensor(0.3550), tensor(0.4606))\n",
      "(tensor(0.2219), tensor(0.7602))\n",
      "(tensor(0.2635), tensor(0.6104))\n",
      "(tensor(0.2985), tensor(0.4721))\n",
      "(tensor(0.2733), tensor(0.6063))\n",
      "(tensor(0.2520), tensor(0.6178))\n",
      "(tensor(0.2650), tensor(0.7188))\n",
      "(tensor(0.2392), tensor(0.7200))\n",
      "(tensor(0.3160), tensor(0.3230))\n",
      "(tensor(0.2840), tensor(0.6695))\n",
      "(tensor(0.2595), tensor(0.5998))\n",
      "(tensor(0.2055), tensor(0.7729))\n",
      "(tensor(0.2847), tensor(0.6892))\n",
      "(tensor(0.2253), tensor(0.6931))\n",
      "(tensor(0.2980), tensor(0.5551))\n",
      "(tensor(0.2385), tensor(0.6813))\n",
      "(tensor(0.2924), tensor(0.5050))\n",
      "(tensor(0.3032), tensor(0.5285))\n",
      "(tensor(0.2637), tensor(0.5188))\n",
      "(tensor(0.2813), tensor(0.5914))\n",
      "(tensor(0.2859), tensor(0.5011))\n",
      "(tensor(0.2297), tensor(0.7183))\n",
      "(tensor(0.2910), tensor(0.4715))\n",
      "(tensor(0.2492), tensor(0.7226))\n",
      "(tensor(0.3289), tensor(0.5716))\n",
      "(tensor(0.3839), tensor(0.3951))\n",
      "(tensor(0.2595), tensor(0.6610))\n",
      "(tensor(0.2844), tensor(0.7263))\n",
      "(tensor(0.2966), tensor(0.6234))\n",
      "(tensor(0.3249), tensor(0.6410))\n",
      "(tensor(0.1646), tensor(0.8277))\n",
      "(tensor(0.2833), tensor(0.5707))\n",
      "(tensor(0.3183), tensor(0.5833))\n",
      "(tensor(0.2906), tensor(0.7066))\n",
      "(tensor(0.2205), tensor(0.7523))\n",
      "(tensor(0.2909), tensor(0.5175))\n",
      "(tensor(0.2924), tensor(0.4321))\n",
      "(tensor(0.2647), tensor(0.6300))\n",
      "(tensor(0.2433), tensor(0.5770))\n",
      "(tensor(0.1885), tensor(0.8293))\n",
      "(tensor(0.2598), tensor(0.5332))\n",
      "(tensor(0.2493), tensor(0.6594))\n",
      "(tensor(0.2269), tensor(0.6860))\n",
      "(tensor(0.2592), tensor(0.5979))\n",
      "(tensor(0.2257), tensor(0.6691))\n",
      "(tensor(0.2805), tensor(0.4924))\n",
      "(tensor(0.3020), tensor(0.4853))\n",
      "(tensor(0.2596), tensor(0.7054))\n",
      "(tensor(0.2560), tensor(0.5118))\n",
      "(tensor(0.2511), tensor(0.4998))\n",
      "(tensor(0.2442), tensor(0.7303))\n",
      "(tensor(0.3351), tensor(0.5557))\n",
      "(tensor(0.3032), tensor(0.5972))\n",
      "(tensor(0.2358), tensor(0.4497))\n",
      "(tensor(0.1980), tensor(0.8017))\n",
      "(tensor(0.2954), tensor(0.5101))\n",
      "(tensor(0.2854), tensor(0.5644))\n",
      "(tensor(0.2810), tensor(0.4933))\n",
      "(tensor(0.2245), tensor(0.7130))\n",
      "(tensor(0.2338), tensor(0.6928))\n",
      "(tensor(0.2815), tensor(0.5871))\n",
      "(tensor(0.2347), tensor(0.7227))\n",
      "(tensor(0.2460), tensor(0.7197))\n",
      "(tensor(0.2927), tensor(0.4676))\n",
      "(tensor(0.3205), tensor(0.5065))\n",
      "(tensor(0.3332), tensor(0.5115))\n",
      "(tensor(0.1913), tensor(0.7725))\n",
      "(tensor(0.3763), tensor(0.3654))\n",
      "(tensor(0.2675), tensor(0.6326))\n",
      "(tensor(0.2808), tensor(0.5457))\n",
      "(tensor(0.1890), tensor(0.8000))\n",
      "(tensor(0.2515), tensor(0.7366))\n",
      "(tensor(0.3021), tensor(0.5708))\n",
      "(tensor(0.1752), tensor(0.8108))\n",
      "(tensor(0.2150), tensor(0.7916))\n",
      "(tensor(0.1879), tensor(0.8214))\n",
      "(tensor(0.2113), tensor(0.7060))\n",
      "(tensor(0.2304), tensor(0.6992))\n",
      "(tensor(0.3243), tensor(0.4949))\n",
      "(tensor(0.2815), tensor(0.5634))\n",
      "(tensor(0.2780), tensor(0.6408))\n",
      "(tensor(0.2110), tensor(0.4821))\n",
      "(tensor(0.2562), tensor(0.6200))\n",
      "(tensor(0.2753), tensor(0.6125))\n",
      "(tensor(0.2327), tensor(0.7291))\n",
      "(tensor(0.2289), tensor(0.6686))\n",
      "(tensor(0.2398), tensor(0.5755))\n",
      "(tensor(0.2806), tensor(0.4555))\n",
      "(tensor(0.3070), tensor(0.4841))\n",
      "(tensor(0.3165), tensor(0.3903))\n",
      "(tensor(0.2835), tensor(0.5360))\n",
      "(tensor(0.2717), tensor(0.6544))\n",
      "(tensor(0.3053), tensor(0.4956))\n",
      "(tensor(0.3040), tensor(0.4888))\n",
      "(tensor(0.2958), tensor(0.5359))\n",
      "(tensor(0.2759), tensor(0.5025))\n",
      "(tensor(0.2155), tensor(0.7559))\n",
      "(tensor(0.1858), tensor(0.7889))\n",
      "(tensor(0.2502), tensor(0.6675))\n",
      "(tensor(0.2139), tensor(0.7682))\n",
      "(tensor(0.2980), tensor(0.6249))\n",
      "(tensor(0.1894), tensor(0.8005))\n",
      "(tensor(0.3142), tensor(0.5523))\n",
      "(tensor(0.2206), tensor(0.7643))\n",
      "(tensor(0.3257), tensor(0.6642))\n",
      "(tensor(0.2846), tensor(0.6191))\n",
      "(tensor(0.2827), tensor(0.5931))\n",
      "(tensor(0.2765), tensor(0.5316))\n",
      "(tensor(0.3274), tensor(0.5474))\n",
      "(tensor(0.2906), tensor(0.3345))\n",
      "(tensor(0.2673), tensor(0.5943))\n",
      "(tensor(0.2118), tensor(0.7944))\n",
      "(tensor(0.3295), tensor(0.4700))\n",
      "(tensor(0.2886), tensor(0.5084))\n",
      "(tensor(0.3248), tensor(0.4880))\n",
      "(tensor(0.2431), tensor(0.7317))\n",
      "(tensor(0.2640), tensor(0.5902))\n",
      "(tensor(0.2750), tensor(0.5464))\n",
      "(tensor(0.2488), tensor(0.6749))\n",
      "(tensor(0.2852), tensor(0.6625))\n",
      "(tensor(0.3176), tensor(0.5912))\n",
      "(tensor(0.2538), tensor(0.6316))\n",
      "(tensor(0.2735), tensor(0.6858))\n",
      "(tensor(0.2947), tensor(0.4973))\n",
      "(tensor(0.2157), tensor(0.6923))\n",
      "(tensor(0.3330), tensor(0.5338))\n",
      "(tensor(0.2725), tensor(0.5927))\n",
      "(tensor(0.1920), tensor(0.8139))\n",
      "(tensor(0.2442), tensor(0.7375))\n",
      "(tensor(0.2692), tensor(0.6494))\n",
      "(tensor(0.3552), tensor(0.4784))\n",
      "(tensor(0.2157), tensor(0.7573))\n",
      "(tensor(0.2713), tensor(0.6506))\n",
      "(tensor(0.3323), tensor(0.4527))\n",
      "(tensor(0.3034), tensor(0.5358))\n",
      "(tensor(0.2608), tensor(0.6827))\n",
      "(tensor(0.2446), tensor(0.6449))\n",
      "(tensor(0.2544), tensor(0.5474))\n",
      "(tensor(0.2477), tensor(0.6550))\n",
      "(tensor(0.2436), tensor(0.6396))\n",
      "(tensor(0.2836), tensor(0.5388))\n",
      "(tensor(0.2750), tensor(0.5459))\n",
      "(tensor(0.2757), tensor(0.5589))\n",
      "(tensor(0.3305), tensor(0.5346))\n",
      "(tensor(0.2959), tensor(0.5340))\n",
      "(tensor(0.3291), tensor(0.5356))\n",
      "(tensor(0.2976), tensor(0.5633))\n",
      "(tensor(0.2370), tensor(0.6703))\n",
      "(tensor(0.1647), tensor(0.8068))\n",
      "(tensor(0.2994), tensor(0.4584))\n",
      "(tensor(0.3004), tensor(0.5286))\n",
      "(tensor(0.2901), tensor(0.3876))\n",
      "(tensor(0.2844), tensor(0.6300))\n",
      "(tensor(0.2703), tensor(0.6158))\n",
      "(tensor(0.2916), tensor(0.6677))\n",
      "(tensor(0.2623), tensor(0.6658))\n",
      "(tensor(0.2043), tensor(0.7661))\n",
      "(tensor(0.2522), tensor(0.6203))\n",
      "(tensor(0.3274), tensor(0.4619))\n",
      "(tensor(0.3045), tensor(0.5210))\n",
      "(tensor(0.2521), tensor(0.5872))\n",
      "(tensor(0.2915), tensor(0.5568))\n",
      "(tensor(0.2102), tensor(0.7700))\n",
      "(tensor(0.2911), tensor(0.4904))\n",
      "(tensor(0.3160), tensor(0.4849))\n",
      "(tensor(0.1890), tensor(0.7490))\n",
      "(tensor(0.2076), tensor(0.6412))\n",
      "(tensor(0.3227), tensor(0.5421))\n",
      "(tensor(0.2340), tensor(0.7604))\n",
      "(tensor(0.2516), tensor(0.6862))\n",
      "(tensor(0.3784), tensor(0.5361))\n",
      "(tensor(0.2950), tensor(0.5490))\n",
      "(tensor(0.2396), tensor(0.6502))\n",
      "(tensor(0.3296), tensor(0.5674))\n",
      "(tensor(0.3030), tensor(0.5650))\n",
      "(tensor(0.2835), tensor(0.5204))\n",
      "(tensor(0.3347), tensor(0.4058))\n",
      "(tensor(0.2838), tensor(0.6741))\n",
      "(tensor(0.2393), tensor(0.6961))\n",
      "(tensor(0.2521), tensor(0.6398))\n",
      "(tensor(0.2033), tensor(0.6927))\n",
      "(tensor(0.2717), tensor(0.4486))\n",
      "(tensor(0.2698), tensor(0.4825))\n",
      "(tensor(0.2969), tensor(0.4710))\n",
      "(tensor(0.2901), tensor(0.4698))\n",
      "(tensor(0.2456), tensor(0.6657))\n",
      "(tensor(0.3344), tensor(0.5386))\n",
      "(tensor(0.2217), tensor(0.7255))\n",
      "(tensor(0.2547), tensor(0.6837))\n",
      "(tensor(0.2398), tensor(0.6979))\n",
      "(tensor(0.2197), tensor(0.6624))\n",
      "(tensor(0.2229), tensor(0.7589))\n",
      "(tensor(0.2297), tensor(0.6788))\n",
      "(tensor(0.2671), tensor(0.7337))\n",
      "(tensor(0.2841), tensor(0.6091))\n",
      "(tensor(0.2269), tensor(0.7357))\n",
      "(tensor(0.2595), tensor(0.5607))\n",
      "(tensor(0.2607), tensor(0.6175))\n",
      "(tensor(0.2253), tensor(0.7717))\n",
      "(tensor(0.3069), tensor(0.5878))\n",
      "(tensor(0.2589), tensor(0.4846))\n",
      "(tensor(0.2131), tensor(0.7858))\n",
      "(tensor(0.2282), tensor(0.6276))\n",
      "(tensor(0.2762), tensor(0.7134))\n",
      "(tensor(0.1901), tensor(0.8125))\n",
      "(tensor(0.2016), tensor(0.7552))\n",
      "(tensor(0.2551), tensor(0.6372))\n",
      "(tensor(0.2284), tensor(0.7182))\n",
      "(tensor(0.1970), tensor(0.7787))\n",
      "(tensor(0.2649), tensor(0.5538))\n",
      "(tensor(0.2824), tensor(0.6184))\n",
      "(tensor(0.2497), tensor(0.6812))\n",
      "(tensor(0.2572), tensor(0.7444))\n",
      "(tensor(0.3358), tensor(0.5170))\n",
      "(tensor(0.2938), tensor(0.4311))\n",
      "(tensor(0.2222), tensor(0.6725))\n",
      "(tensor(0.2088), tensor(0.7606))\n",
      "(tensor(0.3216), tensor(0.4971))\n",
      "(tensor(0.3122), tensor(0.5741))\n",
      "(tensor(0.2679), tensor(0.5661))\n",
      "(tensor(0.2234), tensor(0.6589))\n",
      "(tensor(0.1999), tensor(0.6095))\n",
      "(tensor(0.2822), tensor(0.7254))\n",
      "(tensor(0.2431), tensor(0.7128))\n",
      "(tensor(0.2971), tensor(0.4728))\n",
      "(tensor(0.3019), tensor(0.5347))\n",
      "(tensor(0.2873), tensor(0.6294))\n",
      "(tensor(0.2414), tensor(0.5933))\n",
      "(tensor(0.3184), tensor(0.5997))\n"
     ]
    }
   ],
   "source": [
    "for i in list_b_d2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "101356b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_b_1 = []\n",
    "list_b_2 = []\n",
    "for i,j in list_b_d2:\n",
    "    list_b_1.append(i)\n",
    "    list_b_2.append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86378ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_b_11 = torch.mean(torch.stack(list_b_1))\n",
    "list_b_21 = torch.mean(torch.stack(list_b_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bebd64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2666)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_b_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd2ea201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6114)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_b_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bdf777ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_g_1 = []\n",
    "list_g_2 = []  \n",
    "for i,j in list_g_d2:\n",
    "    list_g_1.append(i)\n",
    "    list_g_2.append(j)\n",
    "\n",
    "list_r_1 = []\n",
    "list_r_2 = []\n",
    "for i,j in list_r_d2:\n",
    "    list_r_1.append(i)\n",
    "    list_r_2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e102d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_g_11 = torch.mean(torch.stack(list_g_1))\n",
    "list_g_21 = torch.mean(torch.stack(list_g_2))\n",
    "\n",
    "list_r_11 = torch.mean(torch.stack(list_r_1))\n",
    "list_r_21 = torch.mean(torch.stack(list_r_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64eb4124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2610) tensor(0.6268)\n"
     ]
    }
   ],
   "source": [
    "print(list_g_11, list_g_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "120682c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2659) tensor(0.6130)\n"
     ]
    }
   ],
   "source": [
    "print(list_r_11, list_r_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee9726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f61b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b6b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eca37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec5d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b1a24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f563c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f037fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kpm_1/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\kpm_1/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a46375c9bd94f9b90c414bece875b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b58993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf408bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class redDiscriminadora(nn.Module):\n",
    "    def __init__(self, dim_z=200, ch_rgb=3, hidd_ch=64):\n",
    "        \n",
    "        super(redDiscriminadora, self).__init__()\n",
    "        \n",
    "        self.z_dim=dim_z\n",
    "        # Necesitamos realizar el proceso inverso\n",
    "        self.main = nn.Sequential(\n",
    "            # la entrada sería 3*128*128\n",
    "            self.gen_blocks(ch_rgb, hidd_ch),\n",
    "            self.gen_blocks(hidd_ch, hidd_ch),\n",
    "            self.gen_blocks(hidd_ch, hidd_ch*2),\n",
    "            self.gen_blocks(hidd_ch*2, hidd_ch*4),\n",
    "            self.gen_blocks(hidd_ch*4, hidd_ch*8),\n",
    "            self.gen_blocks(hidd_ch*8, 1,f_layer=True)  # Obtenemos un \"Tensor\" 1*128*128\n",
    "        )\n",
    "    # Para mejorar la estética y evitar redundancia de código se usa una función generadora de bloques secuenciales\n",
    "    def gen_blocks(self, inp_ch, out_ch, kernel=4, stride=2, padding=1, f_layer=False):\n",
    "        if not f_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp_ch, out_ch, kernel, stride, padding, bias = False), # Probando bias = False\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU( inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp_ch, out_ch, kernel, 1, 0, bias = False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, input_arr):\n",
    "        y = self.main(input_arr)\n",
    "        return y.view(len(y), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0f5d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kpm_1/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\kpm_1/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a68d80f6aa8404cbab8a419ba0d3244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# or any of these variants\n",
    "model2 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a123d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a1874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "tensor([[[ 1.0083, -0.4761, -0.4273,  0.0387, -0.3786, -0.0781],\n",
      "         [ 0.4278, -0.5613,  0.2452, -0.2636, -0.6475, -0.6469],\n",
      "         [ 1.6446, -0.1629,  0.7711, -0.5876,  0.4439,  1.9078],\n",
      "         [ 0.3066,  0.4844,  0.0432,  0.3786, -1.2087,  0.5091],\n",
      "         [ 0.6042,  0.1448, -0.7015, -0.9291, -0.2092, -0.0070],\n",
      "         [ 1.3501,  0.7757, -0.5407, -0.6645,  0.3473, -0.0482]],\n",
      "\n",
      "        [[-0.4951, -0.4273,  0.4197, -0.9586, -0.6651,  2.3684],\n",
      "         [ 0.8673,  1.7543,  0.0346, -0.1023,  0.6514, -0.4703],\n",
      "         [ 0.0598, -0.5231,  2.1681,  0.4273,  1.1144,  0.3807],\n",
      "         [-2.3568, -0.6518, -0.6550,  1.0352, -0.0619,  0.6226],\n",
      "         [ 0.1649,  0.7319, -1.3704, -1.1830,  0.1528, -0.4004],\n",
      "         [ 1.0432,  2.2963, -0.3127,  0.1884, -0.6242, -1.4861]],\n",
      "\n",
      "        [[-0.8237, -0.5084, -0.7774, -0.6410, -1.2019,  1.0415],\n",
      "         [ 0.4631, -1.0239, -0.8442,  0.3804, -0.8742, -0.3651],\n",
      "         [-0.7925,  0.8926,  0.3491, -0.1281,  0.8988,  0.2211],\n",
      "         [-0.8991, -1.1511,  1.8582,  0.2825,  1.4155, -0.0343],\n",
      "         [ 0.9479,  0.9002, -0.9537, -0.4739, -1.2447,  0.4226],\n",
      "         [ 1.0955,  0.5882,  0.1664,  0.6835,  0.2538, -1.0726]],\n",
      "\n",
      "        [[-0.5939, -1.1422, -0.3137,  0.6976,  0.2337, -1.8186],\n",
      "         [-0.1780,  1.5492, -1.3857, -1.2641,  1.4983, -1.0246],\n",
      "         [ 0.2444,  1.2671,  1.1589, -0.6241, -0.7668, -1.8212],\n",
      "         [-0.0669, -2.0665,  1.0833,  0.0298,  0.7591, -0.3371],\n",
      "         [-0.7826,  0.2704,  0.1582,  0.1538, -0.4901,  0.2335],\n",
      "         [ 1.2116, -1.3827,  0.3825, -0.4892,  0.8224,  1.0815]],\n",
      "\n",
      "        [[-0.0045, -0.3424,  1.0704,  0.0977, -0.3688, -0.2765],\n",
      "         [-0.1789, -0.1849,  0.5162,  0.0117,  0.5057, -1.0787],\n",
      "         [ 0.4412, -0.1197, -0.6952,  0.2614, -1.5414,  0.2937],\n",
      "         [-0.1787, -1.1921, -0.8898, -0.9271,  0.7805, -0.0315],\n",
      "         [-1.4002,  1.0989, -0.4697,  0.4803, -0.0670, -0.6456],\n",
      "         [ 1.5472, -1.7554,  0.6737, -1.6645, -0.9054, -0.6936]],\n",
      "\n",
      "        [[-1.2011, -0.2758,  0.5040, -0.2014,  1.0031, -0.6181],\n",
      "         [-1.0647,  0.9181, -0.4832,  1.2051,  0.4403, -0.2280],\n",
      "         [ 1.4353,  1.0656,  1.0285, -0.3640,  0.1022,  1.2096],\n",
      "         [-0.6473, -1.3664, -1.0262, -0.6944, -0.5906,  2.1867],\n",
      "         [-0.1634, -1.1552,  0.3267, -0.5930,  0.9922, -0.7798],\n",
      "         [-0.9703,  0.2409, -0.3612,  0.6783, -0.5460, -0.5375]]])\n",
      "########\n",
      "tensor([[[ 0.0804]],\n",
      "\n",
      "        [[ 0.1038]],\n",
      "\n",
      "        [[-0.0264]],\n",
      "\n",
      "        [[-0.1031]],\n",
      "\n",
      "        [[-0.2176]],\n",
      "\n",
      "        [[-0.0148]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# pool of square window of size=3, stride=2\n",
    "m = nn.AvgPool2d(6, stride=1)\n",
    "# pool of non-square window\n",
    "# m = nn.AvgPool2d(2)\n",
    "input = torch.randn(6,6,6)\n",
    "print('########')\n",
    "print(input)\n",
    "output = m(input)\n",
    "print('########')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b598ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0362fbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\kpm_1/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b18c878baf04241b2b360c589008efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b69d0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d7e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\kpm_1/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34942ac24c1d450894fd5878ac123ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inc = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c82ab7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56aab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5733dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e86524d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96c5e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 750 Ti'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "421a6f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1346, 0.0377, 0.1268],\n",
      "        [0.1918, 0.2815, 0.5484],\n",
      "        [0.6454, 0.8762, 0.5755],\n",
      "        [0.2259, 0.3468, 0.7197],\n",
      "        [0.1290, 0.4407, 0.9190]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca15aa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4.], device='cuda:0')\n",
      "tensor([2., 5.], device='cuda:0')\n",
      "tensor([ 0.3448, -0.4560], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.device('cuda')\n",
    "\n",
    "x = torch.tensor([1., 3.]).cuda()\n",
    "# x.device is device(type='cuda', index=0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    # allocates a tensor on GPU 0\n",
    "    a = torch.tensor([1., 2.], device=cuda)\n",
    "\n",
    "    # transfers a tensor from CPU to GPU 0\n",
    "    b = torch.tensor([1., 2.]).cuda()\n",
    "    # a.device and b.device are device(type='cuda', index=0)\n",
    "\n",
    "    # You can also use ``Tensor.to`` to transfer a tensor:\n",
    "    b2 = torch.tensor([1., 2.]).to(device=cuda)\n",
    "    # b.device and b2.device are device(type='cuda', index=1)\n",
    "\n",
    "    c = a + b\n",
    "    print(c)\n",
    "    # c.device is device(type='cuda', index=0)\n",
    "\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    # z.device is device(type='cuda', index=0)\n",
    "\n",
    "    # even within a context, you can specify the device\n",
    "    # (or give a GPU index to the .cuda call)\n",
    "    d = torch.randn(2, device=cuda)\n",
    "    print(d)\n",
    "    # d.device, e.device, and f.device are all device(type='cuda', index=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
